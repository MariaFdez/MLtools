colnames(TrueData)<-c(realcolnames[1],realcolnames[2],"category")
ggplot()+
geom_point(aes(x=Bou.Points[,1],y=Bou.Points[,2]),data=Bou.Points, lwd=1)+
geom_point(aes(x=Po.points[,1],y=Po.points[,2], colour=category),data=Po.points, alpha=1/4, pch=1, lwd=1)+
geom_point(aes(x=TrueData[,1], y=TrueData[,2], colour=category), data=TrueData, pch=18, lwd=3)+
xlab("Weight") +
ylab("Height")
}
Graph.KNN(data[,1:2],data[,3],1)
RealData<-X[,1:2]
X<-data[,1:2]
y<-data[,3]
Y<-y
realcategories<-unique(Y)
realcategories<-as.character(realcategories)
realcolnames<-colnames(X)
#creating the grid
xlen <- ylen <- 100
X1<-seq(min(X[,1]),max(X[,1]),len=xlen)
X2<-seq(min(X[,2]),max(X[,2]),len=ylen)
data<-matrix(0,(xlen*ylen),2)
colnames(data)<-c(realcolnames[1],realcolnames[2])
is<-1
for (i in 1:xlen){
for (j in 1: ylen){
data[is,]<-c(X1[i],X2[j])
is<-is+1
}
}
##getting the labels for grid points
#labels<- MLtools::KNN.k(X=data,Y=Y,k=k,obj="predict",RealData=X[,1:2])
labels<- KNN.k(X=data,Y=Y,k=k,obj="predict",RealData=X[,1:2])
KNN.k <- function (X,Y,k, obj="train",RealData=NULL){
# test the inputs
not_empty(X); not_empty(Y);
if (obj=="train") {
assert_that(nrow(X)==length(Y))
}
is.string(obj); assert_that(obj %in% c("train", "predict"))
is.count(k);
if (obj=="predict") {
assert_that(not_empty(RealData) &
ncol(RealData)==ncol(X) &
nrow(RealData)==length(Y))
}
#how many observations
noObs<-nrow(X)
##Path in case we wnt to train data
if(obj=="train"){
Distances<-matrix(0,noObs,noObs)
for(i in 1:noObs){
#probe of the current observation
probe <- as.numeric(X[i,])
probeExpanded <- matrix(rep(probe, each=noObs), nrow=noObs)
#distances:
Distances[i,]<-(rowSums((abs(X -probeExpanded))^2) )^(1/2)
}
#neighbors of each point
neighbors<- matrix(0,nrow(Distances),nrow(Distances))
neighbors <- apply(Distances, 2, order)
ModeNeigh<- rep(NA,noObs)
indexes <- t(neighbors[2:(k+1),]) #take only the k th neighbours
indexes.labels <-matrix(0,noObs,k)
#identifying the label that should have the observation
for(i in 1:noObs){
for(j in 1:k){
ind<-indexes[i,j]
indexes.labels[i,j] <-Y[ind]
}
}
predictedClass<-rep(NA,noObs)
#choose the label of the mode category
for (s in 1: noObs){
predictedClass[s]<-as.numeric(names(table(indexes.labels[s,]))[which.max(table(indexes.labels[s,]))])
}
}
#in case we want to predict with the real data values:
if(obj=="predict"){
noReal<-nrow(RealData)
Distances<-matrix(0,noObs,noReal)
for(i in 1:noObs){
#probe of the current observation
probe <- as.numeric(X[i,])
probeExpanded <- matrix(rep(probe, each=noReal), nrow=noReal)
#distances:
Distances[i,]<-(rowSums((abs(RealData -probeExpanded))^2) )^(1/2)
}
#neighbors of each point
neighbors<- matrix(0,noObs,nrow(Distances))
neighbors <- apply(Distances, 1, order)
indexes <- t(neighbors[1:k,]) #take only the k th neighbours
if(k > 1){
indexes.labels <-matrix(0,noObs,k)
#identifying the label that should have the observation
for(i in 1:noObs){
for(j in 1:k){
ind<-indexes[i,j]
indexes.labels[i,j] <-Y[ind]
}
}
predictedClass<-rep(NA,noObs)
#choose the label of the mode category
for (s in 1: noObs){
predictedClass[s]<-as.numeric(names(table(indexes.labels[s,]))[which.max(table(indexes.labels[s,]))])
}
}
if (k==1){
predictedClass<-indexes
}
}
# examine the performance, available only if training
if (obj=="train") {
errorCount <- table(predictedClass, Y)
accuracy <- mean(predictedClass==as.numeric(Y))
} else if (obj == "predict") {
errorCount <- NA
accuracy <- NA
}
# return the results
return(list(predictedClasses=predictedClass,
accuracy=accuracy,
errorCount=errorCount))
}
x1 <- c(978783,1052488,1039495,1056795,1125545,1536011,1616461,1388507,1608121,1416574,1704919,2653310,2208399,1896304,1957401)
x2 <- c(12645844,12343453,4137266,12229065, 12554668,8856611,12137668,11545424,9253718,8863474,15145969,12793921,14593861,15161586,15785243)
Y <- c(rep("Cats",5),rep("Dogs",5),rep("Lions",5))
X <- as.data.frame(cbind(x1,x2))
data <- cbind(X,Y)
Y<-data[,3]
X<-[,1:2]
X<-data[,1:2]
realcategories<-unique(Y)
realcategories<-as.character(realcategories)
#take the name of the X's
realcolnames<-colnames(X)
#creating the grid
xlen <- ylen <- 100
X1<-seq(min(X[,1]),max(X[,1]),len=xlen)
X2<-seq(min(X[,2]),max(X[,2]),len=ylen)
data<-matrix(0,(xlen*ylen),2)
colnames(data)<-c(realcolnames[1],realcolnames[2])
is<-1
for (i in 1:xlen){
for (j in 1: ylen){
data[is,]<-c(X1[i],X2[j])
is<-is+1
}
}
labels<- KNN.k(X=data,Y=Y,k=k,obj="predict",RealData=X)
library(assertthat)
labels<- KNN.k(X=data,Y=Y,k=k,obj="predict",RealData=X)
k<-1
labels<- KNN.k(X=data,Y=Y,k=k,obj="predict",RealData=X)
dataLabel<-cbind(data,labels$predictedClasses)
cbind(data,labels$predictedClasses)
labels$predictedClasses
data
nrow(data)-length(labels$predictedClasses)
data<-as.data.frame(data)
dataLabel<-cbind(data,labels$predictedClasses)
View(dataLabel)
dataLabel<-cbind(data,t(labels$predictedClasses))
View(dataLabel)
KNN.k <- function (X,Y,k, obj="train",RealData=NULL){
# test the inputs
not_empty(X); not_empty(Y);
if (obj=="train") {
assert_that(nrow(X)==length(Y))
}
is.string(obj); assert_that(obj %in% c("train", "predict"))
is.count(k);
if (obj=="predict") {
assert_that(not_empty(RealData) &
ncol(RealData)==ncol(X) &
nrow(RealData)==length(Y))
}
#how many observations
noObs<-nrow(X)
##Path in case we wnt to train data
if(obj=="train"){
Distances<-matrix(0,noObs,noObs)
for(i in 1:noObs){
#probe of the current observation
probe <- as.numeric(X[i,])
probeExpanded <- matrix(rep(probe, each=noObs), nrow=noObs)
#distances:
Distances[i,]<-(rowSums((abs(X -probeExpanded))^2) )^(1/2)
}
#neighbors of each point
neighbors<- matrix(0,nrow(Distances),nrow(Distances))
neighbors <- apply(Distances, 2, order)
ModeNeigh<- rep(NA,noObs)
indexes <- t(neighbors[2:(k+1),]) #take only the k th neighbours
indexes.labels <-matrix(0,noObs,k)
#identifying the label that should have the observation
for(i in 1:noObs){
for(j in 1:k){
ind<-indexes[i,j]
indexes.labels[i,j] <-Y[ind]
}
}
predictedClass<-rep(NA,noObs)
#choose the label of the mode category
for (s in 1: noObs){
predictedClass[s]<-as.numeric(names(table(indexes.labels[s,]))[which.max(table(indexes.labels[s,]))])
}
}
#in case we want to predict with the real data values:
if(obj=="predict"){
noReal<-nrow(RealData)
Distances<-matrix(0,noObs,noReal)
for(i in 1:noObs){
#probe of the current observation
probe <- as.numeric(X[i,])
probeExpanded <- matrix(rep(probe, each=noReal), nrow=noReal)
#distances:
Distances[i,]<-(rowSums((abs(RealData -probeExpanded))^2) )^(1/2)
}
#neighbors of each point
neighbors<- matrix(0,noObs,nrow(Distances))
neighbors <- apply(Distances, 1, order)
indexes <- t(neighbors[1:k,]) #take only the k th neighbours
if(k > 1){
indexes.labels <-matrix(0,noObs,k)
#identifying the label that should have the observation
for(i in 1:noObs){
for(j in 1:k){
ind<-indexes[i,j]
indexes.labels[i,j] <-Y[ind]
}
}
predictedClass<-rep(NA,noObs)
#choose the label of the mode category
for (s in 1: noObs){
predictedClass[s]<-as.numeric(names(table(indexes.labels[s,]))[which.max(table(indexes.labels[s,]))])
}
}
if (k==1){
for(s in 1:noObs){
ind<-indexes[s]
predictedClass[s]<-Y[ind]
}
}
}
}
# examine the performance, available only if training
if (obj=="train") {
errorCount <- table(predictedClass, Y)
accuracy <- mean(predictedClass==as.numeric(Y))
} else if (obj == "predict") {
errorCount <- NA
accuracy <- NA
}
# return the results
return(list(predictedClasses=predictedClass,
accuracy=accuracy,
errorCount=errorCount))
}
KNN.k <- function (X,Y,k, obj="train",RealData=NULL){
# test the inputs
not_empty(X); not_empty(Y);
if (obj=="train") {
assert_that(nrow(X)==length(Y))
}
is.string(obj); assert_that(obj %in% c("train", "predict"))
is.count(k);
if (obj=="predict") {
assert_that(not_empty(RealData) &
ncol(RealData)==ncol(X) &
nrow(RealData)==length(Y))
}
#how many observations
noObs<-nrow(X)
##Path in case we wnt to train data
if(obj=="train"){
Distances<-matrix(0,noObs,noObs)
for(i in 1:noObs){
#probe of the current observation
probe <- as.numeric(X[i,])
probeExpanded <- matrix(rep(probe, each=noObs), nrow=noObs)
#distances:
Distances[i,]<-(rowSums((abs(X -probeExpanded))^2) )^(1/2)
}
#neighbors of each point
neighbors<- matrix(0,nrow(Distances),nrow(Distances))
neighbors <- apply(Distances, 2, order)
ModeNeigh<- rep(NA,noObs)
indexes <- t(neighbors[2:(k+1),]) #take only the k th neighbours
indexes.labels <-matrix(0,noObs,k)
#identifying the label that should have the observation
for(i in 1:noObs){
for(j in 1:k){
ind<-indexes[i,j]
indexes.labels[i,j] <-Y[ind]
}
}
predictedClass<-rep(NA,noObs)
#choose the label of the mode category
for (s in 1: noObs){
predictedClass[s]<-as.numeric(names(table(indexes.labels[s,]))[which.max(table(indexes.labels[s,]))])
}
}
#in case we want to predict with the real data values:
if(obj=="predict"){
noReal<-nrow(RealData)
Distances<-matrix(0,noObs,noReal)
for(i in 1:noObs){
#probe of the current observation
probe <- as.numeric(X[i,])
probeExpanded <- matrix(rep(probe, each=noReal), nrow=noReal)
#distances:
Distances[i,]<-(rowSums((abs(RealData -probeExpanded))^2) )^(1/2)
}
#neighbors of each point
neighbors<- matrix(0,noObs,nrow(Distances))
neighbors <- apply(Distances, 1, order)
indexes <- t(neighbors[1:k,]) #take only the k th neighbours
if(k > 1){
indexes.labels <-matrix(0,noObs,k)
#identifying the label that should have the observation
for(i in 1:noObs){
for(j in 1:k){
ind<-indexes[i,j]
indexes.labels[i,j] <-Y[ind]
}
}
predictedClass<-rep(NA,noObs)
#choose the label of the mode category
for (s in 1: noObs){
predictedClass[s]<-as.numeric(names(table(indexes.labels[s,]))[which.max(table(indexes.labels[s,]))])
}
}
if (k==1){
for(s in 1:noObs){
ind<-indexes[s]
predictedClass[s]<-Y[ind]
}
}
}
# examine the performance, available only if training
if (obj=="train") {
errorCount <- table(predictedClass, Y)
accuracy <- mean(predictedClass==as.numeric(Y))
} else if (obj == "predict") {
errorCount <- NA
accuracy <- NA
}
# return the results
return(list(predictedClasses=predictedClass,
accuracy=accuracy,
errorCount=errorCount))
}
labels<- KNN.k(X=data,Y=Y,k=k,obj="predict",RealData=X)
KNN.k <- function (X,Y,k, obj="train",RealData=NULL){
# test the inputs
not_empty(X); not_empty(Y);
if (obj=="train") {
assert_that(nrow(X)==length(Y))
}
is.string(obj); assert_that(obj %in% c("train", "predict"))
is.count(k);
if (obj=="predict") {
assert_that(not_empty(RealData) &
ncol(RealData)==ncol(X) &
nrow(RealData)==length(Y))
}
#how many observations
noObs<-nrow(X)
##Path in case we wnt to train data
if(obj=="train"){
Distances<-matrix(0,noObs,noObs)
for(i in 1:noObs){
#probe of the current observation
probe <- as.numeric(X[i,])
probeExpanded <- matrix(rep(probe, each=noObs), nrow=noObs)
#distances:
Distances[i,]<-(rowSums((abs(X -probeExpanded))^2) )^(1/2)
}
#neighbors of each point
neighbors<- matrix(0,nrow(Distances),nrow(Distances))
neighbors <- apply(Distances, 2, order)
ModeNeigh<- rep(NA,noObs)
indexes <- t(neighbors[2:(k+1),]) #take only the k th neighbours
indexes.labels <-matrix(0,noObs,k)
#identifying the label that should have the observation
for(i in 1:noObs){
for(j in 1:k){
ind<-indexes[i,j]
indexes.labels[i,j] <-Y[ind]
}
}
predictedClass<-rep(NA,noObs)
#choose the label of the mode category
for (s in 1: noObs){
predictedClass[s]<-as.numeric(names(table(indexes.labels[s,]))[which.max(table(indexes.labels[s,]))])
}
}
#in case we want to predict with the real data values:
if(obj=="predict"){
noReal<-nrow(RealData)
Distances<-matrix(0,noObs,noReal)
for(i in 1:noObs){
#probe of the current observation
probe <- as.numeric(X[i,])
probeExpanded <- matrix(rep(probe, each=noReal), nrow=noReal)
#distances:
Distances[i,]<-(rowSums((abs(RealData -probeExpanded))^2) )^(1/2)
}
#neighbors of each point
neighbors<- matrix(0,noObs,nrow(Distances))
neighbors <- apply(Distances, 1, order)
indexes <- t(neighbors[1:k,]) #take only the k th neighbours
if(k > 1){
indexes.labels <-matrix(0,noObs,k)
#identifying the label that should have the observation
for(i in 1:noObs){
for(j in 1:k){
ind<-indexes[i,j]
indexes.labels[i,j] <-Y[ind]
}
}
predictedClass<-rep(NA,noObs)
#choose the label of the mode category
for (s in 1: noObs){
predictedClass[s]<-as.numeric(names(table(indexes.labels[s,]))[which.max(table(indexes.labels[s,]))])
}
}
if (k==1){
predictedClass<-rep(NA,noObs)
for(s in 1:noObs){
ind<-indexes[s]
predictedClass[s]<-Y[ind]
}
}
}
# examine the performance, available only if training
if (obj=="train") {
errorCount <- table(predictedClass, Y)
accuracy <- mean(predictedClass==as.numeric(Y))
} else if (obj == "predict") {
errorCount <- NA
accuracy <- NA
}
# return the results
return(list(predictedClasses=predictedClass,
accuracy=accuracy,
errorCount=errorCount))
}
labels<- KNN.k(X=data,Y=Y,k=k,obj="predict",RealData=X)
dataLabel<-cbind(data,t(labels$predictedClasses))
dataLabel<-cbind(data,labels$predictedClasses)
Tpoints<-matrix(0,xlen*ylen,4)
plus <- 0
for (i in 1:xlen){
for (j in 2:ylen){
if(dataLabel[(j+plus),3] == dataLabel[(j+plus-1),3]){
Tpoints[(j+plus),4]<-0
Tpoints[(j+plus),1:3]<-as.numeric(dataLabel[(j+plus),1:3])
}else{
Tpoints[(j+plus),4]<-1
Tpoints[(j+plus),1:3]<-as.numeric(dataLabel[(j+plus),1:3])
}
}
plus <- plus + ylen
}
Tpoints<-as.data.frame(Tpoints)
##Changing the animals to it's category name
for(i in 1:nrow(Tpoints)){
if(Tpoints[i,3]==1){
Tpoints[i,3]<-realcategories[1]
}
if(Tpoints[i,3]==2){
Tpoints[i,3] <- realcategories[2]
}
if(Tpoints[i,3]==3){
Tpoints[i,3] <- realcategories[3]
}
}
##Changing the type of point to either Boundary or Point
for(i in 1:nrow(Tpoints)){
if(Tpoints[i,4]==1){
Tpoints[i,4]<-"Boundary"
}
if(Tpoints[i,4]==0){
Tpoints[i,4] <- "Point"
}
}
colnames(Tpoints)<-c(realcolnames[1],realcolnames[2],"category","type")
Tpoints<- Tpoints[Tpoints$category != 0, ]
Bou.Points<-Tpoints[Tpoints$type == "Boundary",]
Po.points<-Tpoints[Tpoints$type == "Point",]
TrueData <- cbind(X,Y)
colnames(TrueData)<-c(realcolnames[1],realcolnames[2],"category")
ggplot()+
geom_point(aes(x=Bou.Points[,1],y=Bou.Points[,2]),data=Bou.Points, lwd=1)+
geom_point(aes(x=Po.points[,1],y=Po.points[,2], colour=category),data=Po.points, alpha=1/4, pch=1, lwd=1)+
geom_point(aes(x=TrueData[,1], y=TrueData[,2], colour=category), data=TrueData, pch=18, lwd=3)+
xlab("Weight") +
ylab("Height")
devtools::document()
setwd("~/Dropbox/Master/2n term/Machine Learning/MLtools")
devtools::document()
devtools::install_github("MariaFdez/MLtools")
devtools::document()
devtools::install_github("MariaFdez/MLtools")
library(MLtools)
?KNN.k
?Graph.KNN
devtools::document()
remove.packages("MLtools")
devtools::install_github("MariaFdez/MLtools")
library(MLtools)
